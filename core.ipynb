{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from zero.imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic blocks, or fundamental components of neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def conv_unit(ni:int, no:int, ks:int=3, stride:int=1, groups:int=1, zero_bn:bool=False, seq:tuple=(1,2,3)):\n",
    "    \"\"\"\n",
    "    The basic unit of convolutional neural networks,\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ni : number of input channels for conv operator\n",
    "    no : number of output channels for conv operator\n",
    "    ks : kernel size of conv operator\n",
    "    stride : stride size of conv operator\n",
    "    groups : number of groups of conv operator\n",
    "    zero_bn : does initialize zero value for weight of batch norm\n",
    "    seq : sequence of operators, operators are represented by interges:\n",
    "          0  :  None\n",
    "          1  :  nn.Conv2d\n",
    "          2  :  nn.ReLU\n",
    "          3  :  nn.BatchNorm2d\n",
    "          ...\n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    a nn.Sequential object\n",
    "    \n",
    "    \"\"\"\n",
    "    unit = []\n",
    "    has_conv = False # if has conv operator\n",
    "    for e in seq:\n",
    "        if e == 0:  # None operator\n",
    "            continue\n",
    "        elif e == 1:  # conv operator\n",
    "            has_conv = True\n",
    "            unit += [nn.Conv2d(ni, no, ks, stride=stride, padding=ks//2, groups=groups, bias=False)]\n",
    "        elif e == 2:  # relu operator\n",
    "            unit += [nn.ReLU(inplace=True)]\n",
    "        elif e == 3:  # bn operator\n",
    "            if has_conv: # if has conv operator\n",
    "                bn = nn.BatchNorm2d(no)  # bn operator's `ni` equal to 'no' of conv op\n",
    "                nn.init.constant_(bn.weight, 0. if zero_bn else 1.) # zero bn only after conv\n",
    "                unit += [bn]\n",
    "            else:  # if has not conv operator\n",
    "                unit += [nn.BatchNorm2d(ni)] # bn operator's `ni` equal to 'ni' of conv op\n",
    "    return nn.Sequential(*unit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# several customized conv units\n",
    "relu_conv_bn = partial(conv_unit, seq = (2,1,3))  # Relu-->Conv-->BN\n",
    "conv_bn_relu = partial(conv_unit, seq = (1,3,2))  # Conv-->BN-->Relu\n",
    "bn_relu_conv = partial(conv_unit, seq = (3,2,1))  # BN-->Relu-->Conv\n",
    "relu_conv = partial(conv_unit, seq = (2,1,0))  # Relu-->Conv\n",
    "conv_bn = partial(conv_unit, seq = (1,3,0))  # Conv-->BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def resnet_basicblock(ni, no, nh, stride:int=1):\n",
    "    \"\"\"\n",
    "    Basic Unit in Residual Networks, ni == no == nh\n",
    "    \n",
    "    Reference:\n",
    "    ----------\n",
    "    Deep Residual Learning for Image Recognition:\n",
    "    https://arxiv.org/abs/1512.03385\n",
    "    \"\"\"\n",
    "    return nn.Sequential(*[*relu_conv_bn(ni, nh, stride=stride).children()], \n",
    "                         *[*relu_conv_bn(nh, no).children()])\n",
    "\n",
    "def resnet_bottleneck(ni, no, nh, stride:int=1, groups:int=1, zero_bn=True):\n",
    "    \"\"\"\n",
    "    Bottleneck Unit in Residual Networks, ni == no > nh\n",
    "    \n",
    "    Reference:\n",
    "    ----------\n",
    "    Deep Residual Learning for Image Recognition:\n",
    "    https://arxiv.org/abs/1512.03385\n",
    "    \"\"\"\n",
    "    return nn.Sequential(*[*relu_conv_bn(ni, nh, ks=1).children()],\n",
    "                         *[*relu_conv_bn(nh, nh, stride=stride, groups=groups).children()],\n",
    "                         *[*relu_conv_bn(nh, no, ks=1, zero_bn=zero_bn).children()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# residential block\n",
    "def preresnet_basicblock(ni, no, nh, stride:int=1):\n",
    "    \"\"\"\n",
    "    Basic Unit in Pre-action Residual Networks, ni == no == nh\n",
    "    \n",
    "    Reference:\n",
    "    ----------\n",
    "    Identity Mappings in Deep Residual Networks:\n",
    "    https://arxiv.org/abs/1603.05027\n",
    "    \"\"\"\n",
    "    return nn.Sequential(*[*bn_relu_conv(ni, nh, stride=stride).children()], \n",
    "                         *[*bn_relu_conv(nh, no).children()])\n",
    "\n",
    "def preresnet_bottleneck(ni, no, nh, stride:int=1, groups:int=1, zero_bn=True):\n",
    "    return nn.Sequential(*[*bn_relu_conv(ni, nh, ks=1).children()],\n",
    "                         *[*bn_relu_conv(nh, nh, stride=stride, groups=groups).children()],\n",
    "                         *[*bn_relu_conv(nh, no, ks=1, zero_bn=zero_bn).children()])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def xception(ni:int, no:int, nh:int, ks:int=3, stride:int=1, zero_bn:bool=False):\n",
    "    \"\"\"\n",
    "    Basic unit in xception networks.\n",
    "    \n",
    "    Reference:\n",
    "    ----------\n",
    "    Xception: Deep Learning with Depthwise Separable Convolutions:\n",
    "    https://arxiv.org/abs/1610.02357\n",
    "    \"\"\"\n",
    "    return nn.Sequential(*[*relu_conv(ni, nh, ks=ks, stride=stride, groups=ni).children()],\n",
    "                        *[*conv_bn(nh, no, ks=1, zero_bn=zero_bn).children()]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): ReLU(inplace=True)\n",
       "   (1): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
       "   (2): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (3): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test xception\n",
    "x = torch.randn(2, 10, 32, 32)\n",
    "m = xception(10, 10, 10, zero_bn=True)\n",
    "m, m[3].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Usually work as the final operator for image processing (classification, object detection, etc.)\n",
    "    Including:\n",
    "    an average pooling op, which downsampling image resolution to 1x1\n",
    "    a linear op, which perform classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, ni, no):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.adaptivepool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(ni, no)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.adaptivepool(x)  # out tensor (N, ni, 1, 1)\n",
    "        out = out.view(out.size(0), -1)  # out tensor (N, ni)\n",
    "        out = self.fc(out)  # out tensor (N, no)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IdentityMapping(nn.Module):\n",
    "    \"\"\"\n",
    "    Identity Mapping between input and output, four cases:\n",
    "    1.  stride == 1 and ni == no\n",
    "        input == output\n",
    "    2.  stride == 1 and ni != no\n",
    "        1x1 conv and bn\n",
    "    3.  stride == 2 and ni == no\n",
    "        maxpool or avgpool\n",
    "    4.  stride == 2 and ni != no\n",
    "        (maxpool or avgpool) and 1x1 conv and bn\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, ni:int, no:int, stride:int=1, pooling_type:str='max'):\n",
    "        super(IdentityMapping, self).__init__()\n",
    "        assert stride == 1 or stride == 2\n",
    "        assert pooling_type == 'max' or pooling_type == 'avg'\n",
    "        unit = []\n",
    "        if stride == 2:\n",
    "            if pooling_type == 'max':\n",
    "                downsample = nn.MaxPool2d(kernel_size=3, stride=stride, padding=1)\n",
    "            elif pooling_type == 'avg':\n",
    "                downsample = nn.AvgPool2d(kernel_size=3, stride=stride, padding=1)\n",
    "            unit.append(downsample)\n",
    "        if ni != no:\n",
    "            unit += conv_bn(ni, no, ks=1, zero_bn=False).children()\n",
    "        self.unit = nn.Sequential(*unit)\n",
    "    def forward(self, x):\n",
    "        out = self.unit(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 32, 32])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test IdentityMapping\n",
    "x = torch.randn(2, 10, 32, 32)\n",
    "m = IdentityMapping(10, 10, stride=1, pooling_type='max')\n",
    "m(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help functions for neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# copy from https://github.com/fastai/fastai/blob/master/fastai/vision/models/xresnet.py\n",
    "def init_cnn(m):\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def num_params(net:nn.Module):\n",
    "    \"Number of parameters of a neural network\"\n",
    "    num_params = 0\n",
    "    for name, param in net.named_parameters():\n",
    "        num = torch.prod(torch.tensor(param.size()))\n",
    "        num_params += num\n",
    "        # print(name, param.size(), num)\n",
    "    return num_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted core.ipynb to zero/core.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py core.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
