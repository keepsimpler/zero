{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "一个深度学习项目的目录结构：\n",
    "    data_loader.py    以batch为单位可遍历的数据\n",
    "    net.py            深度学习的网络模型、误差函数、测量函数\n",
    "    train.py          训练一个epoch的训练数据\n",
    "    evaluate.py       评估一个epoch的评估数据\n",
    "    train_and_evaluate.py  训练并评估数据，记录日志，记录参数，记录效果，调用train和evaluate\n",
    "    train_main.py     训练和评估的主程序，初始化模型和数据等，并调用train_and_evaluate\n",
    "    utils.py          辅助函数\n",
    "    params.json       模型的超参数\n",
    "    /data             数据目录，所有数据在此\n",
    "    /runs             运行目录，所有运行时记录在此"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一步，获得数据 Data Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_loader import fetch_dataloader\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['train', 'val']\n",
    "data_dir = 'data/MNIST'\n",
    "\n",
    "json_path = 'params.json'\n",
    "params = utils.Params(json_path)\n",
    "\n",
    "dataloaders = fetch_dataloader(types, data_dir, params)\n",
    "\n",
    "train_dl = dataloaders['train']\n",
    "val_dl = dataloaders['val']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据一个mini－batch数据的维度：［mini－batch大小，inChannel，Height，Width torch.Size([64, 784]) ；和其分类： tensor([ 6,  2,  9,  4,  2,  1,  9,  1,  9,  4,  7,  1,  1,  8,\n",
      "         2,  3,  7,  2,  8,  4,  2,  4,  9,  9,  3,  9,  9,  7,\n",
      "         7,  5,  3,  3,  1,  8,  3,  8,  7,  3,  8,  5,  7,  9,\n",
      "         6,  3,  2,  2,  1,  2,  5,  0,  9,  1,  0,  9,  7,  5,\n",
      "         0,  8,  9,  0,  8,  0,  4,  9])\n"
     ]
    }
   ],
   "source": [
    "for data, target in train_dl:\n",
    "    print('训练数据一个mini－batch数据的维度：［mini－batch大小，inChannel，Height，Width', \n",
    "          data.size(), '；和其分类：',target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl.dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二步，建模 modeling of neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import net\n",
    "\n",
    "# use GPU if available\n",
    "params.cuda = torch.cuda.is_available()\n",
    "\n",
    "model = net.Net(params).cuda() if params.cuda else net.Net(params)\n",
    "optimizer = optim.Adam(model.parameters(), lr=params.learning_rate)\n",
    "\n",
    "# fetch loss function and metrics\n",
    "loss_fn = net.loss_fn\n",
    "metrics = net.metrics\n",
    "\n",
    "# set model to training mode\n",
    "model.train()\n",
    "\n",
    "# summary for current training loop and a running average object for loss\n",
    "summ = []\n",
    "loss_avg = utils.RunningAverage()\n",
    "\n",
    "for i, (train_batch, labels_batch) in enumerate(train_dl):\n",
    "    if i == 500:\n",
    "        break\n",
    "    \n",
    "    train_batch.requires_grad = True\n",
    "    \n",
    "    # compute model output and loss\n",
    "    output_batch = model(train_batch)\n",
    "    loss = loss_fn(output_batch, labels_batch)\n",
    "\n",
    "    # clear previous gradients, compute gradients of all tensors wrt loss\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # performs updates using calculated gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    # Evaluate summaries only once in a while\n",
    "    if i % params.save_summary_steps == 0:\n",
    "        # extract data from torch tensors, move to cpu, convert to numpy arrays\n",
    "        output_batch = output_batch.data.cpu().numpy()\n",
    "        labels_batch = labels_batch.data.cpu().numpy()\n",
    "\n",
    "        # compute all metrics on this batch\n",
    "        summary_batch = {metric:metrics[metric](output_batch, labels_batch)\n",
    "                         for metric in metrics}\n",
    "        summary_batch['loss'] = loss.data.item()\n",
    "        summ.append(summary_batch)\n",
    "\n",
    "    # update the average loss\n",
    "    loss_avg.update(loss.data.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.00000e-06 *\n",
      "       -6.3776)\n",
      "tensor(1.00000e-04 *\n",
      "       -4.1262)\n",
      "tensor(1.00000e-03 *\n",
      "       -3.8412)\n",
      "tensor(1.00000e-03 *\n",
      "       -1.7876)\n"
     ]
    }
   ],
   "source": [
    "loss.data\n",
    "for tag, value in model.named_parameters():\n",
    "    print(value.grad.data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.594458438287154"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inFeatures = 28 * 28\n",
    "outFeatures = 10\n",
    "numSamples = 60000\n",
    "scale = (2+10)/2\n",
    "numSamples / (scale * (inFeatures + outFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of ModuleList(\n",
       "  (0): Linear(in_features=784, out_features=30, bias=True)\n",
       "  (1): Linear(in_features=30, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
