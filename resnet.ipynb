{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from zero.imports import *\n",
    "from zero.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PartialResStage(nn.Module):\n",
    "    \"\"\"\n",
    "    Stage in a residual network, usually the units in a residual network are divided into\n",
    "    stages according to feature (image) resolution.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ni : number of input channels of the stage, 本stage的入channel数\n",
    "    no : number of output channels of the stage, 本stage的出channel数\n",
    "    nh : number of hidden channels of basic units in the stage, 内部channel数\n",
    "    nu : number of basic units in the stage, unit数\n",
    "    stride : stride size of conv op in First unit\n",
    "    Unit : class of the basic unit, Unit class has calling format:\n",
    "        Unit(ni:int, no:int, nh:int, stride:int=1, **kwargs)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, ni:int, no:int, nh:int, nu:int, stride:int, Unit:nn.Module,\n",
    "                 a:int=1, **kwargs):\n",
    "        super(PartialResStage, self).__init__()\n",
    "        assert a < nu - 2\n",
    "        self.a, self.nu = a, nu\n",
    "        print(self.a, self.nu)\n",
    "        # the first unit, stride size determine if downsample or not\n",
    "        self.unit0 = Unit(ni, no, nh, stride=stride, **kwargs) \n",
    "        self.idmapping0 = IdentityMapping(ni, no, stride=stride) \n",
    "        units = []\n",
    "        for i in range(nu - 1):\n",
    "            units += [Unit(no, no, nh, stride=1, **kwargs)] #resnet_bottleneck\n",
    "        self.units = nn.ModuleList(units)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x_next = self.unit0(x) + self.idmapping0(x)\n",
    "        x_pre = torch.zeros_like(x_next)\n",
    "        x_sum = torch.zeros_like(x_next)\n",
    "        for i, unit in enumerate(self.units):\n",
    "            x_sum += x_next\n",
    "            if i < self.a:\n",
    "                x = x_next + x_pre\n",
    "                x_pre = x\n",
    "            elif i < self.nu - 2:\n",
    "                x = x_next + x_pre\n",
    "            else:\n",
    "                x = x_next + x_sum\n",
    "            x_next = unit(x)\n",
    "        \n",
    "        return x_next\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResStage(nn.Module):\n",
    "    \"\"\"\n",
    "    Stage in a residual network, usually the units in a residual network are divided into\n",
    "    stages according to feature (image) resolution.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ni : number of input channels of the stage, 本stage的入channel数\n",
    "    no : number of output channels of the stage, 本stage的出channel数\n",
    "    nh : number of hidden channels of basic units in the stage, 内部channel数\n",
    "    nu : number of basic units in the stage, unit数\n",
    "    stride : stride size of conv op in First unit\n",
    "    Unit : class of the basic unit, Unit class has calling format:\n",
    "        Unit(ni:int, no:int, nh:int, stride:int=1, **kwargs)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, ni:int, no:int, nh:int, nu:int, stride:int, Unit:nn.Module, **kwargs):\n",
    "        super(ResStage, self).__init__()\n",
    "        # the first unit, stride size determine if downsample or not\n",
    "        self.unit0 = Unit(ni, no, nh, stride=stride, **kwargs) \n",
    "        self.idmapping0 = IdentityMapping(ni, no, stride=stride) \n",
    "        units = []\n",
    "        for i in range(nu - 1):\n",
    "            units += [Unit(no, no, nh, stride=1, **kwargs)] #resnet_bottleneck\n",
    "        self.units = nn.ModuleList(units)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.unit0(x) + self.idmapping0(x)\n",
    "        for i, unit in enumerate(self.units):\n",
    "            x = unit(x) + x\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def resnet_stem(ni:int=3, no:int=64):\n",
    "    \"\"\"Stem stage in resnet\n",
    "    \"\"\"\n",
    "    return nn.Sequential(*[*conv_bn_relu(ni, 32, stride=2).children()],  #downsample\n",
    "                         *[*conv_bn_relu(32, 32, stride=1).children()],\n",
    "                         *[*conv_bn_relu(32, no, stride=1).children()],\n",
    "                         nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  #downsample\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResNet(nn.Sequential):\n",
    "    \"\"\"\n",
    "    Residual Network\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    nhs : number of hidden channels for all stages\n",
    "    nos : number of output channels for all stages\n",
    "    nus : number of units of all stages\n",
    "    strides : stride sizes of all stages\n",
    "    Stem : class of the stem layer, Stem class should has calling format:\n",
    "        Stem(ni:int, no:int)\n",
    "    Stage : class of the stages, Stage class has calling format:\n",
    "        Stage(ni:int, no:int, nh:int, nu:int, stride:int, Unit:nn.Module, **kwargs)\n",
    "    Unit : class of the basic units\n",
    "    c_in : number of input channels of the whole network\n",
    "    c_out : number of output channels (features) of the whole network\n",
    "    kwargs : additional args to Unit class\n",
    "    \"\"\"\n",
    "    def __init__(self, nhs, nos, nus, strides, Stem:nn.Module, Stage:nn.Module, Unit:nn.Module,\n",
    "                 c_in:int=3, c_out:int=1000, **kwargs):\n",
    "        super(ResNet, self).__init__()\n",
    "        stem = Stem(c_in, nhs[0])\n",
    "        stages = []\n",
    "        ni = nhs[0]\n",
    "        for i in range(len(nhs)):\n",
    "            stages += [Stage(ni, nos[i], nhs[i], nus[i], strides[i], Unit, **kwargs)]\n",
    "            ni = nos[i]\n",
    "        classifier = Classifier(nos[-1], c_out)\n",
    "        super().__init__(\n",
    "            stem,\n",
    "            *stages,\n",
    "            classifier\n",
    "        )\n",
    "        init_cnn(self)\n",
    "        \n",
    "        \n",
    "def resnet50(c_in:int=3, c_out:int=1000):\n",
    "    return ResNet(nhs = [64, 128, 256, 512], nos = [256, 512, 1024, 2048],\n",
    "                  nus = [3,4,6,3], strides = [1,2,2,2], Stem = resnet_stem, Stage = ResStage,\n",
    "                  Unit = resnet_bottleneck,\n",
    "                  c_in=c_in, c_out=c_out)\n",
    "\n",
    "def resnet101(c_in:int=3, c_out:int=1000):\n",
    "    return ResNet(nhs = [64, 128, 256, 512], nos = [256, 512, 1024, 2048],\n",
    "                  nus = [3,4,23,3], strides = [1,2,2,2], Stem = resnet_stem, Stage = ResStage, \n",
    "                  Unit = resnet_bottleneck,\n",
    "                  c_in=c_in, c_out=c_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25576264)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### our folded stage classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DualStage(nn.Module):\n",
    "    def __init__(self, ni:int, no:int, nh:int, nu:int, stride:int, Unit:nn.Module, **kwargs):\n",
    "        assert nu >= 2\n",
    "        super(DualStage, self).__init__()\n",
    "        # the first unit, stride size determine if downsample or not\n",
    "        self.unit0 = Unit(ni, no, nh, stride=stride, **kwargs) \n",
    "        self.idmapping0 = IdentityMapping(ni, no, stride=stride) \n",
    "        self.unit1 = Unit(no, no, nh, stride=1, **kwargs) \n",
    "        units = []\n",
    "        for i in range(nu - 2):\n",
    "            units += [Unit(no, no, nh, stride=1, **kwargs)] #resnet_bottleneck\n",
    "        self.units = nn.ModuleList(units)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x1 = self.unit0(x) + self.idmapping0(x)\n",
    "        x2 = self.unit1(x1) + x1\n",
    "        for i, unit in enumerate(self.units):\n",
    "            if i%2 == 0:\n",
    "                x1 = unit(x2) + x1\n",
    "            elif i%2 == 1:\n",
    "                x2 = unit(x1) + x2\n",
    "        return x2 if i%2 == 1 else x1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TripleStage(nn.Module):\n",
    "    \"\"\"\n",
    "    Stage in a residual network, usually the units in a residual network are divided into\n",
    "    stages according to feature (image) resolution.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ni : number of input channels of the stage, 本stage的入channel数\n",
    "    no : number of output channels of the stage, 本stage的出channel数\n",
    "    nh : number of hidden channels of basic units in the stage, 内部channel数\n",
    "    nu : number of basic units in the stage, unit数\n",
    "    stride : stride size of conv op in First unit\n",
    "    Unit : class of the basic unit, Unit class has calling format:\n",
    "        Unit(ni:int, no:int, nh:int, stride:int=1, **kwargs)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, ni:int, no:int, nh:int, nu:int, stride:int, Unit:nn.Module, **kwargs):\n",
    "        assert nu >= 4\n",
    "        super(TripleStage, self).__init__()\n",
    "        # the first unit, stride size determine if downsample or not\n",
    "        self.unit0 = Unit(ni, no, nh, stride=stride, **kwargs) \n",
    "        self.idmapping0 = IdentityMapping(ni, no, stride=stride) \n",
    "        self.unit1 = Unit(no, no, nh, stride=1, **kwargs) \n",
    "        self.unit2 = Unit(no, no, nh, stride=1, **kwargs) \n",
    "        units = []\n",
    "        for i in range(nu - 3):\n",
    "            units += [Unit(no, no, nh, stride=1, **kwargs)] #resnet_bottleneck\n",
    "        self.units = nn.ModuleList(units)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x1 = self.unit0(x) + self.idmapping0(x)\n",
    "        x2 = self.unit1(x1) + x1\n",
    "        x3 = self.unit2(x2) + x2\n",
    "        for i, unit in enumerate(self.units):\n",
    "            if i%4 == 0:\n",
    "                x2 = unit(x3) + x2\n",
    "            elif i%4 == 1:\n",
    "                x1 = unit(x2) + x1\n",
    "            elif i%4 == 2:\n",
    "                x2 = unit(x1) + x2\n",
    "            elif i%4 == 3:\n",
    "                x3 = unit(x2) + x3\n",
    "        return x2 if i%4 == 0 else x1 if i%4 == 1 else x2 if i%4 == 2 else x3 #if i%4 == 3\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class QuadStage(nn.Module):\n",
    "    \"\"\"\n",
    "    Stage in a residual network, usually the units in a residual network are divided into\n",
    "    stages according to feature (image) resolution.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ni : number of input channels of the stage, 本stage的入channel数\n",
    "    no : number of output channels of the stage, 本stage的出channel数\n",
    "    nh : number of hidden channels of basic units in the stage, 内部channel数\n",
    "    nu : number of basic units in the stage, unit数\n",
    "    stride : stride size of conv op in First unit\n",
    "    Unit : class of the basic unit, Unit class has calling format:\n",
    "        Unit(ni:int, no:int, nh:int, stride:int=1, **kwargs)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, ni:int, no:int, nh:int, nu:int, stride:int, Unit:nn.Module, **kwargs):\n",
    "        assert nu >= 5\n",
    "        super(QuadStage, self).__init__()\n",
    "        # the first unit, stride size determine if downsample or not\n",
    "        self.unit0 = Unit(ni, no, nh, stride=stride, **kwargs) \n",
    "        self.idmapping0 = IdentityMapping(ni, no, stride=stride) \n",
    "        self.unit1 = Unit(no, no, nh, stride=1, **kwargs) \n",
    "        self.unit2 = Unit(no, no, nh, stride=1, **kwargs) \n",
    "        self.unit3 = Unit(no, no, nh, stride=1, **kwargs) \n",
    "        units = []\n",
    "        for i in range(nu - 4):\n",
    "            units += [Unit(no, no, nh, stride=1, **kwargs)] #resnet_bottleneck\n",
    "        self.units = nn.ModuleList(units)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x1 = self.unit0(x) + self.idmapping0(x)\n",
    "        x2 = self.unit1(x1) + x1\n",
    "        x3 = self.unit2(x2) + x2\n",
    "        x4 = self.unit3(x3) + x3\n",
    "        for i, unit in enumerate(self.units):\n",
    "            if i % 6 == 0:\n",
    "                x3 = unit(x4) + x3\n",
    "            elif i % 6 == 1:\n",
    "                x2 = unit(x3) + x2\n",
    "            elif i % 6 == 2:\n",
    "                x1 = unit(x2) + x1\n",
    "            elif i % 6 == 3:\n",
    "                x2 = unit(x1) + x2\n",
    "            elif i % 6 == 4:\n",
    "                x3 = unit(x2) + x3\n",
    "            elif i % 6 == 5:\n",
    "                x4 = unit(x3) + x4\n",
    "        return x3 if i%6 == 0 or i%6 ==4 else x2 if i%6 == 1 or i%6 == 3 else x1 if i%6 == 2 else x4 # if i%6 == 5        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FiveStage(nn.Module):\n",
    "    \"\"\"\n",
    "    Stage in a residual network, usually the units in a residual network are divided into\n",
    "    stages according to feature (image) resolution.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ni : number of input channels of the stage, 本stage的入channel数\n",
    "    no : number of output channels of the stage, 本stage的出channel数\n",
    "    nh : number of hidden channels of basic units in the stage, 内部channel数\n",
    "    nu : number of basic units in the stage, unit数\n",
    "    stride : stride size of conv op in First unit\n",
    "    Unit : class of the basic unit, Unit class has calling format:\n",
    "        Unit(ni:int, no:int, nh:int, stride:int=1, **kwargs)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, ni:int, no:int, nh:int, nu:int, stride:int, Unit:nn.Module, **kwargs):\n",
    "        assert nu >= 6\n",
    "        super(FiveStage, self).__init__()\n",
    "        # the first unit, stride size determine if downsample or not\n",
    "        self.unit0 = Unit(ni, no, nh, stride=stride, **kwargs) \n",
    "        self.idmapping0 = IdentityMapping(ni, no, stride=stride) \n",
    "        self.unit1 = Unit(no, no, nh, stride=1, **kwargs) \n",
    "        self.unit2 = Unit(no, no, nh, stride=1, **kwargs) \n",
    "        self.unit3 = Unit(no, no, nh, stride=1, **kwargs) \n",
    "        self.unit4 = Unit(no, no, nh, stride=1, **kwargs) \n",
    "        units = []\n",
    "        for i in range(nu - 5):\n",
    "            units += [Unit(no, no, nh, stride=1, **kwargs)] #resnet_bottleneck\n",
    "        self.units = nn.ModuleList(units)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x1 = self.unit0(x) + self.idmapping0(x)\n",
    "        x2 = self.unit1(x1) + x1\n",
    "        x3 = self.unit2(x2) + x2\n",
    "        x4 = self.unit3(x3) + x3\n",
    "        x5 = self.unit4(x4) + x4\n",
    "        for i, unit in enumerate(self.units):\n",
    "            if i % 8 == 0:\n",
    "                x4 = unit(x5) + x4\n",
    "            elif i % 8 == 1:\n",
    "                x3 = unit(x4) + x3\n",
    "            elif i % 8 == 2:\n",
    "                x2 = unit(x3) + x2\n",
    "            elif i % 8 == 3:\n",
    "                x1 = unit(x2) + x1\n",
    "            elif i % 8 == 4:\n",
    "                x2 = unit(x1) + x2\n",
    "            elif i % 8 == 5:\n",
    "                x3 = unit(x2) + x3\n",
    "            elif i % 8 == 6:\n",
    "                x4 = unit(x3) + x4\n",
    "            elif i % 8 == 7:\n",
    "                x5 = unit(x4) + x5\n",
    "        return x4 if i%8 == 0 or i%8 == 6 else x3 if i%8 == 1 or i%8 == 5 else x2 if i%8 == 2 or i%8 == 4 else x1 if i%8 == 3 else x5 # if i%8 == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def folded_resnet(Stem, Stage, Unit, ni:int=32, num_stages:int=4, num_units:int=6, exp:int=2,\n",
    "                  bottle_scale:int=1, first_downsample:bool=True, c_in:int=3, c_out:int=10, **kwargs):\n",
    "    \"\"\"\n",
    "    A folded residual network.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Stem : class of the stem layer.\n",
    "    Stage : class of the stages.\n",
    "    Unit : class of the basic blocks.\n",
    "    ni  :  number of input channels of the first stage \n",
    "            equal to number of output channels of the stem layer.\n",
    "    num_stages : number of stages.\n",
    "    num_units : number of units per stage.\n",
    "    exp : expansion coefficient for number of channels increasing with stages.\n",
    "    bottle_scale : bottleneck coefficient.\n",
    "    first_downsample : does downsample at the first stage.\n",
    "    c_in : number of input channels of the stem layer.\n",
    "    c_out : \n",
    "    \"\"\"\n",
    "    nhs = [ni * exp ** i for i in range(num_stages)] # [ni] + [exp*ni] + [exp*ni] + [exp*ni]\n",
    "    nos = [nh*bottle_scale for nh in nhs]\n",
    "    nus = [num_units] * num_stages  # all stages have the same number of units\n",
    "    strides = [1 if i==0 and not first_downsample else 2 for i in range(num_stages)]\n",
    "    print(nhs, nos, nus, strides)\n",
    "    return ResNet(nhs = nhs, nos = nos,\n",
    "                  nus = nus, strides = strides, Stem = Stem, Stage = Stage,\n",
    "                  Unit = Unit,\n",
    "                  c_in=c_in, c_out=c_out, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 64, 64, 64, 64] [64, 64, 64, 64, 64] [10, 10, 10, 10, 10] [1, 2, 2, 2, 2]\n",
      "2 10\n",
      "2 10\n",
      "2 10\n",
      "2 10\n",
      "2 10\n"
     ]
    }
   ],
   "source": [
    "model = folded_resnet(Stem = conv_bn, Stage = PartialResStage, Unit = xception, ni=64,\n",
    "                      num_stages=5, num_units=10, exp=1, first_downsample=False, zero_bn=True, a = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(242506)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2,3,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    out = model(x)\n",
    "    out.mean().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export: Before Export, First Remove `zero` in `from zero.bla import *`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted resnet.ipynb to zero/resnet.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py resnet.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
