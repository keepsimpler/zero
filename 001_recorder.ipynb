{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim import SGD\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "# Data CIFAR10\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "val_loader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zero.models.resnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18()\n",
    "\n",
    "outputs = {}\n",
    "\n",
    "def save_output(name):\n",
    "    def hook(module, input, output):\n",
    "        outputs[name] = output\n",
    "    return hook\n",
    "\n",
    "#\n",
    "for name, module in model.named_modules():\n",
    "    if list(module.children()) == []:\n",
    "        module.register_forward_hook(save_output(name))\n",
    "\n",
    "grad_outputs = {}\n",
    "\n",
    "def save_grad_output(name):\n",
    "    def hook(module, grad_input, grad_output):\n",
    "        grad_outputs[name] = grad_output\n",
    "    return hook\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if list(module.children()) == []:\n",
    "        module.register_backward_hook(save_grad_output(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import CategoricalAccuracy, Loss\n",
    "\n",
    "lr = 1e-3\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "trainer = create_supervised_trainer(model, optimizer, F.cross_entropy, device=device)\n",
    "evaluator = create_supervised_evaluator(model,\n",
    "                                        metrics={'nll': Loss(F.cross_entropy)},\n",
    "                                        device=device)\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_training_loss(engine):\n",
    "    iter = (engine.state.iteration - 1) % len(train_loader) + 1\n",
    "    if iter % log_interval == 0:\n",
    "        for key, value in outputs.items():\n",
    "            print(key, value.data.mean().cpu().item(), value.data.std().cpu().item(),\n",
    "            value.data.norm().cpu().item(), value.data.norm(p=3).cpu().item())\n",
    "        for key, value in grad_outputs.items():\n",
    "            print(key, value[0].data.mean().cpu().item(), value[0].data.std().cpu().item(),\n",
    "            value[0].data.norm().cpu().item(), value[0].data.norm(p=3).cpu().item())\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     print(name, param.data.mean().cpu().item(), param.data.std().cpu().item(),\n",
    "        #     param.data.norm().cpu().item(), param.data.norm(p=3).cpu().item(),\n",
    "        #     param.data.round().mode()[0])\n",
    "        print(\"Epoch[{}] Iteration[{}/{}] Loss: {:.2f}\"\n",
    "              \"\".format(engine.state.epoch, iter, len(train_loader), engine.state.output))\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(engine):\n",
    "    evaluator.run(train_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    avg_nll = metrics['nll']\n",
    "#     for key, value in outputs.items():\n",
    "#         print(key, value)\n",
    "#     for key, value in grad_outputs.items():\n",
    "#         print(key, value)\n",
    "    print(\"Training Results - Epoch: {}  Avg loss: {:.2f}\"\n",
    "          .format(engine.state.epoch, avg_nll))\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(engine):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    avg_nll = metrics['nll']\n",
    "    print(\"Validation Results - Epoch: {}  Avg loss: {:.2f}\"\n",
    "          .format(engine.state.epoch, avg_nll))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "epochs = 1\n",
    "trainer.run(train_loader, max_epochs=epochs)\n",
    "with open('output.txt', 'w') as f:\n",
    "    f.write(cap.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qqqq\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
